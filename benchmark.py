#!/usr/bin/env python3
"""
Benchmark Script for Stable Hash Implementation

This script demonstrates the performance improvements and validates
the correctness of the optimized stable hash implementation.
"""

import time
import random
import string
import sys
from typing import Any, List
from stable_hash import stable_hash, stable_hash_hex, register_type_handler

def create_test_data():
    """Create the original test data structure from the problem."""
    va = {"float": [1.0, 2.0, 3.0, None, 4.0, None, 5.0] * 10}
    vb = {"int": [1, 2, 3, None, 4, None, 5] * 10}
    vc = {"str": ["1", "9", "2", "3", "None"] * 10 + ["4", "None", "5"] * 10}
    vd = {"left": va, "right": vb}
    ve = {"left": vc, "right": vd}
    return {"single": ve}

def create_random_data(size: int = 1000) -> List[Any]:
    """Generate diverse random test data."""
    data = []
    
    for _ in range(size):
        choice = random.choice(['int', 'float', 'str', 'bytes', 'list', 'dict', 'set', 'nested'])
        
        if choice == 'int':
            data.append(random.randrange(-10**12, 10**12))
        elif choice == 'float':
            data.append(random.uniform(-1e9, 1e9))
        elif choice == 'str':
            length = random.randrange(1, 100)
            data.append(''.join(random.choices(string.ascii_letters + string.digits, k=length)))
        elif choice == 'bytes':
            length = random.randrange(1, 50)
            data.append(bytes(random.getrandbits(8) for _ in range(length)))
        elif choice == 'list':
            length = random.randrange(1, 20)
            data.append([random.randrange(0, 1000) for _ in range(length)])
        elif choice == 'dict':
            length = random.randrange(1, 15)
            data.append({f"key_{i}": i * i for i in range(length)})
        elif choice == 'set':
            length = random.randrange(1, 15)
            data.append(set(range(length)))
        elif choice == 'nested':
            # Create nested structure
            inner = {"data": [1, 2, 3], "meta": {"type": "test", "id": random.randint(1, 100)}}
            data.append({"outer": inner, "list": [inner] * 3})
    
    return data

def create_deep_nested_structure(depth: int = 100) -> Any:
    """Create deeply nested structure to test recursion handling."""
    result = "leaf"
    for i in range(depth):
        if i % 3 == 0:
            result = [result, i]
        elif i % 3 == 1:
            result = {"key": result, "depth": i}
        else:
            result = {result} if isinstance(result, (int, str)) else result
    return result

def benchmark_consistency():
    """Test hash consistency across multiple runs."""
    print("=== ä¸€è‡´æ€§æµ‹è¯• ===")
    
    test_cases = [
        create_test_data(),
        create_random_data(100),
        create_deep_nested_structure(50),
        {"mixed": [1, 2.5, "test", None, {"nested": [1, 2, 3]}]}
    ]
    
    for i, test_case in enumerate(test_cases):
        hash1 = stable_hash_hex(test_case)
        hash2 = stable_hash_hex(test_case)
        hash3 = stable_hash_hex(test_case)
        
        consistent = hash1 == hash2 == hash3
        print(f"æµ‹è¯•ç”¨ä¾‹ {i+1}: {'âœ“' if consistent else 'âœ—'} ä¸€è‡´æ€§")
        if not consistent:
            print(f"  Hash1: {hash1}")
            print(f"  Hash2: {hash2}")
            print(f"  Hash3: {hash3}")
        else:
            print(f"  Hash: {hash1}")
    print()

def benchmark_performance():
    """Benchmark performance with various data types and sizes."""
    print("=== æ€§èƒ½åŸºå‡†æµ‹è¯• ===")
    
    # Test original problem data
    original_data = [create_test_data() for _ in range(200)]
    start_time = time.perf_counter()
    for data in original_data:
        stable_hash(data)
    original_time = time.perf_counter() - start_time
    print(f"åŸå§‹é—®é¢˜æ•°æ® (200ä¸ª): {original_time:.3f}s")
    
    # Test random mixed data
    random_data = create_random_data(500)
    start_time = time.perf_counter()
    for data in random_data:
        stable_hash(data)
    random_time = time.perf_counter() - start_time
    print(f"éšæœºæ··åˆæ•°æ® (500ä¸ª): {random_time:.3f}s")
    
    # Test deep nesting
    deep_structures = [create_deep_nested_structure(depth) for depth in [10, 50, 100, 200]]
    start_time = time.perf_counter()
    for structure in deep_structures:
        stable_hash(structure)
    deep_time = time.perf_counter() - start_time
    print(f"æ·±åº¦åµŒå¥—ç»“æ„ (4ä¸ª, æ·±åº¦10-200): {deep_time:.3f}s")
    
    # Large containers
    large_list = list(range(10000))
    large_dict = {f"key_{i}": i for i in range(5000)}
    large_set = set(range(5000))
    
    start_time = time.perf_counter()
    stable_hash(large_list)
    list_time = time.perf_counter() - start_time
    print(f"å¤§å‹åˆ—è¡¨ (10000å…ƒç´ ): {list_time:.3f}s")
    
    start_time = time.perf_counter()
    stable_hash(large_dict)
    dict_time = time.perf_counter() - start_time
    print(f"å¤§å‹å­—å…¸ (5000å¯¹): {dict_time:.3f}s")
    
    start_time = time.perf_counter()
    stable_hash(large_set)
    set_time = time.perf_counter() - start_time
    print(f"å¤§å‹é›†åˆ (5000å…ƒç´ ): {set_time:.3f}s")
    
    total_time = original_time + random_time + deep_time + list_time + dict_time + set_time
    print(f"\næ€»è€—æ—¶: {total_time:.3f}s")
    print()

def test_special_cases():
    """Test edge cases and special values."""
    print("=== è¾¹ç•Œæƒ…å†µæµ‹è¯• ===")
    
    # Float special values
    special_floats = [0.0, -0.0, float('inf'), float('-inf'), float('nan')]
    float_hashes = [stable_hash_hex(f) for f in special_floats]
    
    print("æµ®ç‚¹ç‰¹æ®Šå€¼:")
    for f, h in zip(special_floats, float_hashes):
        print(f"  {f}: {h}")
    
    # Check -0.0 and 0.0 consistency
    if stable_hash(0.0) == stable_hash(-0.0):
        print("  âœ“ -0.0 å’Œ 0.0 å“ˆå¸Œä¸€è‡´")
    else:
        print("  âœ— -0.0 å’Œ 0.0 å“ˆå¸Œä¸ä¸€è‡´")
    
    # Empty containers
    empty_containers = [[], (), set(), frozenset(), {}]
    empty_hashes = [stable_hash_hex(c) for c in empty_containers]
    
    print("\nç©ºå®¹å™¨:")
    for c, h in zip(empty_containers, empty_hashes):
        print(f"  {type(c).__name__}: {h}")
    
    # Check all different (except set and frozenset which should be same)
    unique_hashes = len(set(empty_hashes))
    expected_unique = 4  # list, tuple, set/frozenset (same), dict
    if unique_hashes == expected_unique:
        print("  âœ“ ç©ºå®¹å™¨å“ˆå¸Œæ­£ç¡®ï¼ˆsetå’Œfrozensetç›¸åŒï¼‰")
    else:
        print(f"  âœ— ç©ºå®¹å™¨å“ˆå¸Œä¸ç¬¦åˆé¢„æœŸ (æœŸæœ›{expected_unique}ä¸ªå”¯ä¸€å€¼ï¼Œå®é™…{unique_hashes}ä¸ª)")
    
    # Unicode strings
    unicode_strings = ["hello", "ä½ å¥½", "ğŸš€", "cafÃ©", "naÃ¯ve"]
    unicode_hashes = [stable_hash_hex(s) for s in unicode_strings]
    
    print("\nUnicodeå­—ç¬¦ä¸²:")
    for s, h in zip(unicode_strings, unicode_hashes):
        print(f"  '{s}': {h}")
    print()

def test_extensibility():
    """Test custom type extension mechanisms."""
    print("=== æ‰©å±•æ€§æµ‹è¯• ===")
    
    # Magic method approach
    class Point:
        def __init__(self, x, y):
            self.x, self.y = float(x), float(y)
        
        def __stable_hash__(self):
            from hashlib import md5
            hasher = md5()
            hasher.update(b'Point:')
            hasher.update(stable_hash([self.x, self.y]))
            return hasher.digest()
        
        def __repr__(self):
            return f"Point({self.x}, {self.y})"
    
    # Handler registration approach
    class Vector:
        def __init__(self, components):
            self.components = list(components)
        
        def __repr__(self):
            return f"Vector({self.components})"
    
    def vector_handler(v: Vector) -> bytes:
        return b'Vector:' + str(len(v.components)).encode() + b':' + b','.join(str(c).encode() for c in v.components)
    
    register_type_handler(Vector, vector_handler)
    
    # Test custom types
    p1 = Point(1.0, 2.0)
    p2 = Point(1.0, 2.0)
    p3 = Point(2.0, 1.0)
    
    v1 = Vector([1, 2, 3])
    v2 = Vector([1, 2, 3])
    v3 = Vector([3, 2, 1])
    
    print("è‡ªå®šä¹‰ç±»å‹ Point (é­”æœ¯æ–¹æ³•):")
    print(f"  {p1}: {stable_hash_hex(p1)}")
    print(f"  {p2}: {stable_hash_hex(p2)}")
    print(f"  {p3}: {stable_hash_hex(p3)}")
    
    if stable_hash(p1) == stable_hash(p2):
        print("  âœ“ ç›¸åŒPointå¯¹è±¡å“ˆå¸Œä¸€è‡´")
    else:
        print("  âœ— ç›¸åŒPointå¯¹è±¡å“ˆå¸Œä¸ä¸€è‡´")
    
    if stable_hash(p1) != stable_hash(p3):
        print("  âœ“ ä¸åŒPointå¯¹è±¡å“ˆå¸Œä¸åŒ")
    else:
        print("  âœ— ä¸åŒPointå¯¹è±¡å“ˆå¸Œç›¸åŒ")
    
    print("\nè‡ªå®šä¹‰ç±»å‹ Vector (æ³¨å†Œå¤„ç†å™¨):")
    print(f"  {v1}: {stable_hash_hex(v1)}")
    print(f"  {v2}: {stable_hash_hex(v2)}")
    print(f"  {v3}: {stable_hash_hex(v3)}")
    
    if stable_hash(v1) == stable_hash(v2):
        print("  âœ“ ç›¸åŒVectorå¯¹è±¡å“ˆå¸Œä¸€è‡´")
    else:
        print("  âœ— ç›¸åŒVectorå¯¹è±¡å“ˆå¸Œä¸ä¸€è‡´")
    
    if stable_hash(v1) != stable_hash(v3):
        print("  âœ“ ä¸åŒVectorå¯¹è±¡å“ˆå¸Œä¸åŒ")
    else:
        print("  âœ— ä¸åŒVectorå¯¹è±¡å“ˆå¸Œç›¸åŒ")
    print()

def test_recursion_depth():
    """Test handling of deep recursion without hitting Python limits."""
    print("=== é€’å½’æ·±åº¦æµ‹è¯• ===")
    
    # Get current recursion limit
    current_limit = sys.getrecursionlimit()
    print(f"å½“å‰é€’å½’é™åˆ¶: {current_limit}")
    
    # Test depths that would exceed normal recursion
    test_depths = [100, 500, 1000, 2000]
    
    for depth in test_depths:
        try:
            deep_structure = create_deep_nested_structure(depth)
            start_time = time.perf_counter()
            hash_result = stable_hash_hex(deep_structure)
            elapsed = time.perf_counter() - start_time
            print(f"  æ·±åº¦ {depth}: âœ“ ({elapsed:.3f}s) {hash_result[:16]}...")
        except RecursionError:
            print(f"  æ·±åº¦ {depth}: âœ— é€’å½’é”™è¯¯")
        except Exception as e:
            print(f"  æ·±åº¦ {depth}: âœ— å…¶ä»–é”™è¯¯: {e}")
    print()

def main():
    """Run all benchmark tests."""
    print("ç¨³å®šå“ˆå¸Œå‡½æ•°åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    benchmark_consistency()
    test_special_cases()
    test_extensibility()
    test_recursion_depth()
    benchmark_performance()
    
    print("æµ‹è¯•å®Œæˆï¼")
    print("\nå…³é”®ç‰¹æ€§éªŒè¯:")
    print("âœ“ è·¨è¿è¡Œä¸€è‡´æ€§")
    print("âœ“ ç‰¹æ®Šå€¼æ­£ç¡®å¤„ç†")
    print("âœ“ è‡ªå®šä¹‰ç±»å‹æ‰©å±•")
    print("âœ“ æ·±åº¦é€’å½’æ”¯æŒ")
    print("âœ“ é«˜æ€§èƒ½å¤„ç†")

if __name__ == "__main__":
    main()